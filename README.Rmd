---
title: "Why does preregistration increase the persuasiveness of evidence? A Bayesian rationalization."
output:
  bookdown::pdf_document2:
    latex_engine: "xelatex"
    toc: false
linestretch: 2
abstract: |
  Preregistration is becoming increasingly popular in the psychological sciences.
  At the same time, many researchers struggle to make precise predictions and feel overwhelmed by the need to prespecify every detail of their analysis plan.
  Should they surrender and discard the idea of preregistration altogether?
  Not at all.
  We argue for the benefits of preregistration beyond strictly confirmatory studies.
  Grounded in Bayesian reasoning, we define a formal objective for preregistration that neither declares changes to a preregistration to be sinful nor punishes rigour.
  This objective rests on the relevance of "theoretical risk", a generalization of type-I error rate, for judging the evidential support for theories.
  We propose that preregistration should aim to reduce the uncertainty in judging the theoretical risk instead of directly limiting the type-I error rate.
  We argue that this reformulation extends the utility of preregistration and is more closely aligned with researchers intuition.
  If we do not know what a researcher did, we have great uncertainty about the theoretical risk they took.
  This uncertainty severely limits the utility of the researchers' evidence.
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

A successful prediction should lend more credibility to a theory than a postdiction, all else equal.
Much has been theorized on this important distinction between exploration and confirmation, discovery and justification, hypothesis-generating and hypothesis-testing and so forth (see XXXX).
To honour this distinction, many researchers preregister their studies to produce results that are considered confirmatory.
Rigorous application of preregistration prevents researchers from reporting a simple confirmatory story for a set of results that were produced by an arduous process of try and error.
The scientific community widely agrees that actively concealing such "trying for results" is misconduct --- but how exactly is it impeding scientific progress?
We believe that a rigorous answer to this question enables us to clear some common misunderstandings that lead researchers to deem preregistration as unfit for their purposes.
These misunderstandings are interesting from a theoretical perspective but also lead to decreased efficiency of the scientific process if researchers misguidedly decide that preregistration is not applicable for their intended study.

One reason why researchers are hesitant to preregister is that they feel too limited by preregistration.
Even researchers who have been persuaded by its advantages sometimes apply strategies to skirt the self-imposed restrictions.
One strategy is to write a loose preregistration, to begin with; another is to deviate from the preregistration afterwards.
To complicate matters further, both strategies may be used with compelling scientific reasoning or with the self-serving intent of generating good looking results no matter the nature of the phenomenon under study.
To summarize, the conundrum is that the current conceptualization of preregistration deem a study "properly" preregistered even if it contains a recipe for p-hacking before data collection but "improper" if the researcher did technically deviate afterwards.
This, of course, goes against common researchers intuition about what is considered exploratory and confirmatory.
We take these issues as signals of a misunderstanding about how preregistration contributes to scientific progress.
In particular, we want to challenge the common view that preregistration somehow cleanly separates confirmatory from exploratory.

Deciding if a study is confirmatory or exploratory is a judgment made by the researcher assessing it.
The issues above arise by delegating this judgment to a simple decision rule.
That is, if something is preregistered, it is confirmatory, and if it is not preregistered, it is exploratory.
This rule is often assumed implicitly as a rule of thumb.
Other times it is stated as the explicit goal of preregistration.
In both cases, it leads to confusion when applied outside specific bounds.
Preregistering an inherently exploratory analysis (like testing dozens of relations) does not make it confirmatory, nor will a carefully conducted confirmatory study become exploratory if the researcher deviates from the preregistration in minor details.
To uphold the simplicity of the decision rule, it is routinely suggested to only preregister when a study is expected to have a low type I error rate by design and will run/be analyzed without changes no matter what.
Under these conditions, the rule holds, but such restricted use makes preregistration a niche solution unable to match the greater problem of replicability in psychology and elsewhere.

We show that this simple decision rule is a special case of a more general conceptualization under Bayesian reasoning.
To that end, we first introduce some tools of Bayesian philosophy of science and map the exploration/confirmation distinction onto a dimensional quantity we call "theoretical risk", which is inversely related to type I error rate.
We then propose two interpretations of how theoretical risk is influenced by preregistration.
The first interpretation corresponds to the traditional application of preregistration to research paradigms that focus on confirmation by maximizing the theoretical risk or equivalently limiting type I error.
The second interpretation is our main contribution and shows the broad applicability of preregistration for both exploratory and confirmatory studies that are implemented as preregistered or have undergone changes.
Under this interpretation, the theoretical risk is not necessarily directly maximized by preregistration, but the uncertainty in judging the theoretical risk is minimized.
This changed viewpoint is crucial for the following reason.
As the name implies, directly maximizing theoretical risk increases the likelihood that a study fails to deliver results favouring the theory.
As we will later show, minimizing the uncertainty around the theoretical risk shares the beneficial properties without increasing the likelihood of a "failed" study.
Let us note that a study that does not result in the evidence a researcher is hoping for is still precious for the scientific process.
Under the current incentive structure, however, many researchers have reason to avoid such outcome and few, if any, have the privilege to operate outside of these incentives.
We, therefore, propose an interpretation of preregistration that increases the expected epistemic value of studies without necessarily increasing the theoretical risk.

# Epistemic value and the Bayesian rationale

Let us start by defining what we mean by expected epistemic value.
If researchers plan to conduct a study, they usually hope it will change their assessment of some theory's verisimilitude (truthlikeness).
In other words, they hope to learn something from conducting the study.
The amount of knowledge researchers gain from a particular study concerning the verisimilitude of a specific theory is what we call epistemic value.
While researchers can not know what exactly they will learn from a study, they can form an expectation.
This expectation is what we call expected epistemic value.
We assume three things about this estimation process and how it relates to choosing a study to conduct.

1. Researchers judge the evidence for or against a hypothesis rationally.
2. They expect other researchers to apply the same rational process.
2. All else equal, researchers try to increase the expected epistemic value for other researchers.

The first assumption leads to our adoption of a Bayesian framework.
Our rationale is as follows.
Researchers that decide to conduct a study are akin to choosing a study to bet on.
They have to "place the bet" by conducting the study, therefore, invest resources and stand to gain epistemic value with some probability.
This conceptualization of choosing a study as a betting problem lets us apply a "Dutch Book" argument.
This argument states that any better must follow the axioms of probability to avoid being "irrational", i.e., accepting bets that lead to sure losses.
Fully developing a Dutch book argument for this problem requires careful consideration of what kind of studies to include as possible bets, defining a conversion rate from the stakes to the reward, and modelling what liberties researchers have in choosing a study.
Without deliberating these concepts further, we find it persuasive that researchers should not violate the axioms of probability if they have some expectation about what they stand to gain with some likelihood from conducting a study.
The axioms of probability are sufficient to derive the famous Bayes formula, on which we will heavily rely for our arguments.
Please note that our decision to adopt this aspect of the Bayesian philosophy of science does not imply anything about the statistical methods researchers use.
In fact, this conceptualization is purposefully reductionistic to be compatible with a wide range of philosophies of science and statistical methods researchers might subscribe to.
Our conclusions can be applied to bayesian and frequentist methods alike.
Of course, frequentist methods are traditionally viewed from a Popperian philosophy of science, but our conclusions are compatible with this view and notable later advancements like the error statistical view.
However, those philosophies of science require a much richer set of assumptions that are not quite necessary for the points we want to make about the value of preregistration.

# Epistemic Value and Theoretical Risk

The first point is that risky predictions create persuasive evidence if they turn out to be correct.
This point is crucial because we attribute much of the appeal of preregistration to this fact.

Let us make some simplifying assumptions and define notation.
We restrict ourselves to consider evidence of a binary nature (either exists or does not) since continuous evidence would lead to some quite involved derivations.
We denote the probability of a hypothesis before observing evidence as $P(H)$ and its complement as $P(¬H) = 1 - P(H)$.
The probability of observing evidence under some hypothesis is $P(E|H)$.
We can calculate the probability of the hypothesis after observing the evidence with help from the Bayes formula:

$$
P(H|E) = \frac{P(H)P(E|H)}{P(E)}
$$

$P(H|E)$ is of great relevance since $P(H|E)$ is often used directly or indirectly as a measure of corroboration of a hypothesis.
In carnaps tradition, in its direct use, it is called corroboration as firmness; in its relation to $P(H)$, it is called increase in firmness.
We refrain from discussing specific measures of corroboration since no measure shows universally better properties than others.
However, it is generally expected that any measure of corroboration increases monotonically with an increase in $P(H|E)$.

In short, we want to increase $P(H|E)$.
Increases in $P(H|E)$ are associated with increased epistemic value, of which we want to maximize the expectation.
So how can we increase $P(H|E)$?
The Bayes formula gives us three options to investigate, namely $P(H)$, $P(E|H)$ and $P(E)$.
The first option leads us to the unsurprising conclusion that higher $P(H)$ leads to higher $P(H|E)$, but the a priori probability of a hypothesis is nothing our study design can change.
The second option is similar commonsense, that is an increase in $P(E|H)$ leads to higher $P(H|E)$.
Consequently, researchers should ensure that their study design allows them to find evidence for their hypothesis in case it is true.
While this truism is strongly related to study design, it is unrelated to preregistration.
So $P(E)$ remains to consider.
Since $P(E)$ is the denominator, increasing it will decrease $P(H|E)$.
So the unlikelier it is to observe evidence, the more it increases the probability of the hypothesis if we do observe it.
In other words, high risk, high reward.

If we equate riskiness with a low probability of obtaining evidence, the Bayesian rationale perfectly aligns with the observation that risky predictions lead to persuasive evidence.
This tension between high risk leading to high reward is central to our consideration of preregistration.
A high risk, high reward strategy is bound to result in many losses that are eventually absorbed by the high gains.
Sustaining many "failed" studies is not exactly aligned with the incentive structure many researchers operate under.
Therefore researchers have an incentive to appear to take more risks than they actually do, which misleads their colleges to give their claims more credence than they deserve.
It is here where preregistrations make their impact.
They try to ensure a proper judgment of the riskiness of a study by making tempering with the appearance of $P(E)$ difficult.

To better understand how preregistrations can do that, let us take a closer look at what contributes to $P(E)$.
Using the law of total probability, we can split $P(E)$ into two terms:

$$
P(E) = P(H)P(E|H) + P(¬H)P(E|¬H)
$$

We already have noted that there is not much to do about $P(H)$ (and hence its counter probability $P(¬H)$), and that it is common sense to increase $P(E|H)$.
The real lever to pull is, therefore, $P(E|¬H)$.
This probability tells us how likely it is that we find evidence when in fact, the theory is not true.
Its counter probability $P(¬E|¬H)= 1 - P(E|¬H)$ is what we call "theoretical risk", because it is the risk a theory takes on in predicting the occurrence of particular evidence in its favour.

```{r, include=FALSE}
bayes <- function(h, eh, enh)(h * eh)/((h * eh) + ((1 - h) * enh))
```

Let us note some interesting properties about theoretical risk $P(¬H|¬E)$.
First, increasing theoretical risk leads to higher $P(H|E)$ (our objective).
Second, if the theoretical risk is smaller than $P(E|H)$ it follows that $P(H|E)$ must decrease when observing the evidence.
Third, if the theoretical risk equals zero, then $P(H|E)$ can at best be equal to $P(H)$ but only if $P(H|E)$ is one.
In other words, observing a sure fact does not lend credence to a hypothesis.

This sounds like a truism but is directly related to Poppers famous criterion of demarcation.
He stated that if it is impossible to prove a hypothesis false, therefore $P(E|¬H) = 1$ or conversely $P(¬E|¬H) = 0$, it can not be a scientific hypothesis (Popper 1962, 39).
We note these relations to underline that the Bayesian rational we apply here is able to reconstruct many commonly held views on riskiness and epistemic value.

# Preregistration Tasked with Increasing the Theoretical Risk

After we discussed that increasing the theoretical risk will increase the epistemic value, it is only natural to task preregistration with maximizing theoretical risk.
In fact, limiting type I error rate is a commonly stated as a goal of preregistration.
While we think it is often beneficial to increase the theorethical risk but it is comes with a cost.


# Theorethical Risk and Statistical Methods 

Preregistration is often discussed in relation to statistical methods, so let us note some relations between $P(E|¬H)$ and statistical methods.
If you consider the overly simplistic case where the research hypothesis is equal to the statistical nill-hypothesis, then the alternative hypothesis is $¬H$, and therefore $P(E|¬H)$ is equivalent to the type I error rate.
Researchers who choose a smaller type I error rate can hence be surer of their results.
However, the research hypothesis is seldomly equal to the statistical null hypothesis.
We argue that $P(E|¬H)$ also encompasses factors outside the statistical realm, most notably the study design and broader analytical strategies.

Statistical methods stand out among these factors because we have a large toolbox for assessing and controlling their contribution to $P(E|¬H)$.
Examples of our ability to exert this control are the setting of type I error rate, the use of corrected fit measures (i.e., adjusted R²), information criteria or cross-validation in machine learning.
These are all tools that help us factor in the tendency of statistical methods to show results even when there are none and are therefore closely related to $P(E|¬H)$  (the probability of observing evidence when in fact, there is none).

The point is that the contribution of statistical methods to $P(E|¬H)$ can be formally assessed.
For many statistical models, $P(E|¬H)$ can be analytically computed under some assumptions.
For those models or assumptions where this is impossible, one can employ Monte Carlo simulation to estimate $P(E|¬H)$.
The precision with which researchers can discuss $P(E|¬H)$ has lured the community concerned with research methods into ignoring other factors that are much more uncertain.
We can not hope to resolve this uncertainty; however, we may discuss its implications.

If one chooses to focus only on the contribution of statistical methods to $P(E|¬H)$, one is bound to underestimate it.
Take, for example, a t-test.
Under ideal circumstances (assumption of independence, normality of residuals, equal variance), it stays true to its type I error rate.
However, researchers might do many very reasonable things in the broader context of the study.
They might exclude outliers, choose to drop an item, enlarge their definition of the population to be sampled, translate their questionnaire, impute missing values, or any number of other things, that all carry a small risk that they obtain evidence despite their hypothesis being false.
Even if the t-test itself perfectly maintains its type I error rate, these factors have to be added to $P(E|¬H)$.
Statistical properties, therefore, only guarantee a lower bound to the quantity we seek to minimize.
Put simply, the only thing we can conclude with certainty is that $P(E|¬H)$ is not lower than what the statistical model guarantees.

# Preregistration Tasked with Decreasing Uncertainty about the Theoretical Risk

The other two assumptions are later necessary to connect individual decisions that affect epistemic value to the research community as a whole.

Observe, that since $P(E|¬H)$.

Please note, that we adopt a Bayesian rational for the meta scientific process of preregistration but that this does not imply any ties to the methods a researcher uses.

However, we aim to show that preregistration is indispensable for adequately judging a much broader range of studies.
To that end, we first rationalize the appreciation for conformation using Bayesian reasoning.
Equipped with some of the basic tools of Bayesian Philosophy of Science, we can move beyond a simple dichotomy of exploration and confirmation.

To that end we show that the appreciation for the distinction between exploration and confirmatory neatly falls in line with Bayesian reasoning connected through a quantity we call *theorethical risk*.
Than we proceed to show that preregistration impacts the theorethical risk via two pathways.
Only considering the one path rationalizes recommendation to employ preregistration only for confirmatory studies, taking both paths together into consideration leads to a much wider applicability of preregistration.


But what exactly have you been cheated of?
This appreciation of confirmatory results falls neatly in line with Bayesian reasoning (XXX).
<!-- We leverage this reasoning to outline two paradigms that rationalize the use of preregistration. -->
In order to apply Bayesian reasoning we have to cast conformation and exploration in terms of probability.
Consider the hypothesis that people who regularly engage in fitness activities are healthier.
A confirmatory story might operationalize regularly as weekly, fitness activity as light jogging and healthy as blood cholesterol level.
A more exploratory study might consider several definitions of "regularly", "fitness activities", and "healthy", e.g. "monthly", "weekly", "daily", or "marathon", "light jogging", "intense cleaning", or "cholesterol", "self rated health", "ability to play tag".
Both studies have some probability to turn up with positive results even in a world where fitness activities do not lead to healthier people, because there are other plausible explanations for the results.
However, for the second study the number of explanations that could lead to evidence in favor, aside from the theory is much greater.
Suppose a researcher actually conducted the second study but is reporting it as if they conducted the first study.
You would feel cheated.
But what exactly have you been cheated of?
In fact, you have been cheated out of the information about all the possibilities that could have brought about this evidence.
We summarize these possibilities as a probability.
Therefore, we argue that confirmatory studies have a low probability of observing evidence in favor of their theory if we assume the theory to be false.
Exploratory studies on the other hand are characterized by a higher probability that they find evidence, even when their hypothesis turns out to be wrong.


We connect the question of exploration vs confirmation to Bayesian reasoning via a quantity we call theoretical risk (we borrow the term from Meehl).

Theoretical risk is the inverse of the probability that one observes evidence in favor of a theory when we assume that the theory does not hold.
We assume that confirmatory studies take a high theoretical risk, compared to exploratory studies which take a low theoretical risk.
The tighter your definition of "evidence in favor" is, the more the probability of observing the evidence is tied to your theory holding.

<!-- Caroline does not see the connection to type I error rate/theoretical risk -->
 
Let us formalize the judgment about a hypothesis (H) given some evidence (E) as the conditional probability $p(H|E)$.

Using Bayes' rule we arrive at:

$$
p(H|E) = \frac{p(H)p(E|H)}{p(H)p(E|H) + p(¬H)p(E|¬H)}
$$


Note the connection to null hypothesis testing.
If H represents the alternative Hypothesis and ¬H represents the Null hypothesis, then $p(E|H)$ is the power, while $p(E|¬H)$ represents the type I/alpha error.
However, generally a theory is richer in content, than equating it with the alternaive hypothesis in Null hypothesis testing.

<!-- continue to justify the importance of theorethical risk -->

The first paradigm is embraced by the open science community and conceptualizes preregistration as a tool to reduce the type I error rate (XXXX).
As we will later show, reducing the type I error rate is indeed a powerful leaver to gather persuasive evidence.
In practice, however, researchers can not reduce the type I error rate at will.
They face three limiting factors.
First, psychological theories tend to be vague.
Some decisions are just not derivable from theory, which makes it extraordinarily difficult to maintain a type I error rate near zero.
Second, researchers are constrained by resource limitations.
One way to counter the first problem is conducting exploratory pilot studies, but running extensive pilot studies is expensive.
Doubling the resources that go into investigating a research question is often just not tenable and mostly beyond the individual researcher to decide.
Third, by reducing the type I error rate the researcher directly increases the likelihood that their study will result in disappointing null results.
A study that fails to deliver results can be crippling to the researchers career.
Depending on individual circumstances, e.g. the theory in question, resources allocated to a study, the career stage of the researcher, a researcher may simply feel unable to reduce the type I error rate to the threshold necessary for a confirmatory study.
Constrained by these factors researchers tasked with writing a preregistration are incentiviced to either give up or to muddle through by being intentionally vague. The latter practice leads to preregistrations stating unspecific assumptions such as "we expect some of the Xs to correlate with some of the Ys".
